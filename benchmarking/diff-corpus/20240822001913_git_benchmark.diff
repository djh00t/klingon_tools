diff --git a/benchmarking/diff-corpus/20240822000507_git_benchmark.diff b/benchmarking/diff-corpus/20240822000507_git_benchmark.diff
new file mode 100644
index 0000000..a140e54
--- /dev/null
+++ b/benchmarking/diff-corpus/20240822000507_git_benchmark.diff
@@ -0,0 +1,173 @@
+diff --git a/benchmarking/diff-corpus/20240822000249_git_benchmark.diff b/benchmarking/diff-corpus/20240822000249_git_benchmark.diff
+new file mode 100644
+index 0000000..9c72230
+--- /dev/null
++++ b/benchmarking/diff-corpus/20240822000249_git_benchmark.diff
+@@ -0,0 +1,167 @@
++diff --git a/benchmarking/diff-corpus/20240822000128_git_benchmark.diff b/benchmarking/diff-corpus/20240822000128_git_benchmark.diff
++new file mode 100644
++index 0000000..d6abf28
++--- /dev/null
+++++ b/benchmarking/diff-corpus/20240822000128_git_benchmark.diff
++@@ -0,0 +1,161 @@
+++diff --git a/benchmarking/diff-corpus/20240821_git_benchmark.diff b/benchmarking/diff-corpus/20240821_git_benchmark.diff
+++new file mode 100644
+++index 0000000..510dbb9
+++--- /dev/null
++++++ b/benchmarking/diff-corpus/20240821_git_benchmark.diff
+++@@ -0,0 +1,155 @@
++++diff --git a/klingon_tools/entrypoints.py b/klingon_tools/entrypoints.py
++++index 10dc4ce..5a37788 100644
++++--- a/klingon_tools/entrypoints.py
+++++++ b/klingon_tools/entrypoints.py
++++@@ -33,31 +33,40 @@ Example:
++++ import logging
++++ from klingon_tools.git_log_helper import get_commit_log
++++ from klingon_tools.log_msg import log_message, set_default_style, set_log_level
++++-from klingon_tools.openai_tools import OpenAITools
+++++# from klingon_tools.openai_tools import OpenAITools
+++++from klingon_tools.litellm_tools import LiteLLMTools
++++ import pytest
++++ import os
++++
++++-
++++ # Suppress logging from the httpx library
++++ logging.getLogger("httpx").setLevel(logging.WARNING)
++++
++++
++++-def ktest():
++++-    """Run pytest and display the results.
+++++def ktest(loglevel="INFO"):
+++++    """
+++++    Run pytest and display the results with the specified log level.
++++
++++     This function runs the tests using pytest and ensures that the logging
++++     output is displayed.
++++
+++++    Args:
+++++        loglevel (str): The logging level to use. Can be one of:
+++++                        'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'.
+++++                        Defaults to 'INFO'.
+++++
++++     Entrypoint:
++++         ktest
++++     """
+++++    # Set the default logging style
++++     set_default_style("pre-commit")
++++-    set_log_level("DEBUG")
+++++
+++++    # Set the logging level based on the passed argument
+++++    set_log_level(loglevel.upper())
++++
++++     # List to capture test results
++++     results = []
++++
++++-    class MyPlugin:
+++++    class TestLogPlugin:
++++         def pytest_runtest_logreport(self, report):
++++             if report.when == "call":
++++                 test_name = report.nodeid
++++@@ -65,8 +74,15 @@ def ktest():
++++                     log_message.info(message=f"{test_name}", status="✅")
++++                     results.append((test_name, "passed"))
++++                 elif report.failed:
++++-                    log_message.error(message=f"{test_name}", status="❌")
++++-                    results.append((test_name, "failed"))
+++++                    # Check if the test is optional and log as warning
+++++                    if "optional" in report.keywords:
+++++                        log_message.warning(
+++++                            message=f"{test_name} (optional)", status="⚠️"
+++++                        )
+++++                        results.append((test_name, "optional-failed"))
+++++                    else:
+++++                        log_message.error(message=f"{test_name}", status="❌")
+++++                        results.append((test_name, "failed"))
++++                     # Print debug info after the log messages
++++                     log_message.debug(message=f"Debug info for {test_name}")
++++                     print(report.longrepr)
++++@@ -74,20 +90,23 @@ def ktest():
++++                     log_message.info(message=f"{test_name}", status="⏭️")
++++                     results.append((test_name, "skipped"))
++++
++++-    # Redirect stdout to suppress pytest output
+++++    # Redirect stdout to suppress pytest output (to prevent double logging)
++++     with open(os.devnull, "w") as devnull:
++++         original_stdout = os.dup(1)
++++         os.dup2(devnull.fileno(), 1)
++++
++++         try:
++++             # Run pytest with the custom plugin
++++-            pytest.main(["tests", "--tb=short"], plugins=[MyPlugin()])
+++++            pytest.main(["tests", "--tb=short"], plugins=[TestLogPlugin()])
++++         finally:
++++             # Restore stdout
++++             os.dup2(original_stdout, 1)
++++
++++-    # Return the results
++++-    return results
+++++    # Return the results in the expected format
+++++    return [
+++++        {"name": test_name, "outcome": outcome}
+++++        for test_name, outcome in results
+++++    ]
++++
++++
++++ def gh_pr_gen_title():
++++@@ -102,11 +121,11 @@ def gh_pr_gen_title():
++++     Example:
++++         gh_pr_gen_title()
++++     """
++++-    # log_message.info("Generating PR title using OpenAITools...")
+++++    # log_message.info("Generating PR title using LiteLLMTools...")
++++     commit_result = get_commit_log("origin/release")
++++     diff = commit_result.stdout
++++-    openai_tools = OpenAITools()
++++-    pr_title = openai_tools.generate_pull_request_title(diff)
+++++    litellm_tools = LiteLLMTools()
+++++    pr_title = litellm_tools.generate_pull_request_title(diff)
++++     print(pr_title)
++++
++++
++++@@ -123,11 +142,11 @@ def gh_pr_gen_summary():
++++     Example:
++++         gh_pr_gen_summary()
++++     """
++++-    # log_message.info("Generating PR summary using OpenAITools...")
+++++    # log_message.info("Generating PR summary using LiteLLMTools...")
++++     commit_result = get_commit_log("origin/release")
++++     diff = commit_result.stdout
++++-    openai_tools = OpenAITools()
++++-    pr_summary = openai_tools.generate_pull_request_summary(diff, dryrun=False)
+++++    litellm_tools = LiteLLMTools()
+++++    pr_summary = litellm_tools.generate_pull_request_summary(diff, dryrun=False)
++++     print(pr_summary)
++++
++++
++++@@ -144,11 +163,11 @@ def gh_pr_gen_context():
++++     Example:
++++         gh_pr_gen_context()
++++     """
++++-    # log_message.info("Generating PR context using OpenAITools...")
+++++    # log_message.info("Generating PR context using LiteLLMTools...")
++++     commit_result = get_commit_log("origin/release")
++++     diff = commit_result.stdout
++++-    openai_tools = OpenAITools()
++++-    pr_context = openai_tools.generate_pull_request_context(diff, dryrun=False)
+++++    litellm_tools = LiteLLMTools()
+++++    pr_context = litellm_tools.generate_pull_request_context(diff, dryrun=False)
++++     print(pr_context)
++++
++++
++++@@ -165,9 +184,9 @@ def gh_pr_gen_body():
++++     Example:
++++         gh_pr_gen_body()
++++     """
++++-    # log_message.info("Generating PR body using OpenAITools...")
+++++    # log_message.info("Generating PR body using LiteLLMTools...")
++++     commit_result = get_commit_log("origin/release")
++++     diff = commit_result.stdout
++++-    openai_tools = OpenAITools()
++++-    pr_body = openai_tools.generate_pull_request_body(diff)
+++++    litellm_tools = LiteLLMTools()
+++++    pr_body = litellm_tools.generate_pull_request_body(diff)
++++     print(pr_body)
